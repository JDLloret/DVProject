---
title: "Home Assignment: Exploratory analysis and visualization"
output: html_document
date: "2025-05-15"
author: "Joan Lloret and Martí Díez"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load libraries

```{r libraries, message=FALSE}
library(ggplot2)
library(ggfortify)
library(factoextra)
library(stats)
library(Rtsne)
library(dplyr)
library(tidyr)
library(patchwork)
library(gridExtra)
library(umap)
library(ggpubr)
```

# QUESTION 1: Load, adapt the data and create metadata
# Load the data files

```{r data}
rep1 <- read.csv("./data/rep1.csv")
rep2 <- read.csv("./data/rep2.csv")
rep3 <- read.csv("./data/rep3.csv")
rep4 <- read.csv("./data/rep4.csv")
```

# Check the dimensions of the data, fix rows and transpose the matrix to ensure the data is properly displayed

```{r}
rows <- nrow(rep1)
columns <- ncol(rep1)
cat("The data set rep1 has", rows, "rows and", columns, "columns.\n")

rows <- nrow(rep2)
columns <- ncol(rep2)
cat("The data set rep2 has", rows, "rows and", columns, "columns.\n")

rows <- nrow(rep3)
columns <- ncol(rep3)
cat("The data set rep3 has", rows, "rows and", columns, "columns.\n")

rows <- nrow(rep4)
columns <- ncol(rep4)
cat("The data set rep4 has", rows, "rows and", columns, "columns.\n")


rownames(rep1) <- rep1$X
rep1$X <- NULL

rownames(rep2) <- rep2$X
rep2$X <- NULL

rownames(rep3) <- rep3$X
rep3$X <- NULL

rownames(rep4) <- rep4$X
rep4$X <- NULL

all_equal <- all(rownames(rep1) == rownames(rep2)) &&
             all(rownames(rep1) == rownames(rep3)) &&
             all(rownames(rep1) == rownames(rep4))
cat("Gene name order identical across datasets:", all_equal, "\n")


rep1 <- t(rep1)
rep2 <- t(rep2)
rep3 <- t(rep3)
rep4 <- t(rep4)

```

# Create the metadata and bind the datasets for posterior analysis

```{r}
replicate <- rep(c("1", "2", "3", "4"), each = nrow(rep1))

A_B_vector <- rep(c("A", "B"), each = nrow(rep1) / 2)

time_stamp <- rep(c("T1", "T2", "T3", "T4", "T5", "T6"), each=1) 


metadata <- data.frame(replicate, A_B_vector, time_stamp)

data <- rbind(rep1, rep2, rep3, rep4)
```



# QUESTION 2: PCA representation
There are three types of PCA representations:
Unscaled, Scaled and Normalized. The unscaled representation uses raw data and can lead to an uneven representation since it can emphasize genes with higher overall expression.
The scaled representation scales and centers the data and highlights changes across conditions.
The normalized representation adjusts for the total expression. This means that each sample has a similar total expression level. This representation is used when we compare samples where the total expression might vary a lot. 
```{r}
set.seed(123)

# UNSCALED PCA
pca_unscaled <- prcomp(data, scale = FALSE)
names(pca_unscaled)

# SCALED PCA
pca_scaled <- prcomp(data, scale = TRUE)
names(pca_scaled)

# NORMALIZE THE DATA
sum_data <- rowSums(data)
normalized_data <- sweep(data, 1, sum_data, "/")

# NORMALIZED PCA
pca_normalized <- prcomp(normalized_data, scale = TRUE)
```


# Plot the PCA representations

# Unscaled PCA plot
```{r}
pca1_unscaled <- fviz_pca_ind(pca_unscaled,
                              geom.ind = "point",
                              habillage = metadata$A_B_vector,
                              addEllipses = TRUE,
                              title = "A/B experiment")

pca2_unscaled <- fviz_pca_ind(pca_unscaled,
                              geom.ind = "point",
                              habillage = metadata$replicate,
                              addEllipses = TRUE,
                              title = "Replicates")


pca1_unscaled + pca2_unscaled + plot_annotation("Unscaled plots")



```

Here we can see first the A/B experiment differences, where they have opposite growths in relation to Dim2. Along to all groups remaining in separate clusters. Not giving any relevant information more that we know they are different. Adding these ellipses helps us see if the data is clustered based on the replicate or the experiment, which could show a possible batch effect.

# Plot full unscaled PCA with ggplot

```{r}
ggplot(pca_unscaled$x, 
       aes(x = PC1, 
           y = PC2, 
           shape = metadata$replicate, 
           size = metadata$A_B_vector, 
           color = metadata$time_stamp))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title="Unscaled PCA", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### CANVIAR EXPLICACIÓ
This plot reinforces the previous statement, showing how the samples group by replicates and experiment, but nothing more relevant except for the fact that each point represents a sample and it can be seen more clearly the clusters grouped by both replicate and type of experiment. 


# Scaled PCA plot


```{r}
pca1_scaled <- fviz_pca_ind(pca_scaled,
                              geom.ind = "point",
                              habillage = metadata$A_B_vector,
                              addEllipses = TRUE,
                              title = "A/B experiment")

pca2_scaled <- fviz_pca_ind(pca_scaled,
                              geom.ind = "point",
                              habillage = metadata$replicate,
                              addEllipses = TRUE,
                              title = "Replicates")


pca1_scaled + pca2_scaled + plot_annotation("Scaled plots")
```

Once scaled we still remain in a similar situation but with a small change, the group 3 cluster has grown covering inside groups 1 and 2, but still with a low relevant information to extract. Therefore the scaling has adapted a bit to take into account big value discrepancies, but the data still needs to be adapted.

# Plot full scaled PCA plot with ggplot


```{r}
ggplot(pca_scaled$x,
       aes(x = PC1,
           y = PC2, 
           shape = metadata$replicate,
           size = metadata$A_B_vector,
           color = metadata$time_stamp))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Scaled PCA", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### CANVIAR EXPLICACIÓ
Here we can see that it stays mostly the same as before. Using this type of data reduces the samples with high variance, and allows us to focus more on the differences in proportion. With scaling there isn't as much batch effect, or at least it is more subtle when looking for differences between samples. 

# Normalized PCA plot

```{r}
pca1_normalized <- fviz_pca_ind(pca_normalized,
                              geom.ind = "point",
                              habillage = metadata$A_B_vector,
                              addEllipses = TRUE,
                              title = "A/B experiment")

pca2_normalized <- fviz_pca_ind(pca_normalized,
                              geom.ind = "point",
                              habillage = metadata$replicate,
                              addEllipses = TRUE,
                              title = "Replicates")


pca1_normalized + pca2_normalized + plot_annotation("Normalized plots")
```

After normalizing we now see bigger changes, but they seem to be caused due to the group B and 3 outlier that makes the whole plot shift, therefore we will have to take these cases into account


# Plot full normalized PCA with ggplot
```{r}
ggplot(pca_normalized$x,
       aes(x = PC1,
           y = PC2, 
           shape = metadata$replicate,
           size = metadata$A_B_vector,
           color = metadata$time_stamp))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Normalized PCA", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### REVISAR EXPLICACIÓ
Here we see that the clusters are grouped in an entirely new way, discriminating by type of experiment and showing clusters of different replicas, but PC2 no longer explains the same-replicate clusters. When normalizing the data by the rowsums it eliminates variability due to differences in the total gene expression found in the samples, and this is useful when focusing on expression patterns that are specific to certain conditions (independently of technical variations in a specific sample).

# Outliers

We need to identify the outliers since they can skew our results. What we'll do is find the max value in all PCAs to find this outlier and remove it from our data to then normalize again to get more accurate results. 

```{r}

# Find outliers
point <- data.frame(pca_normalized$x)

absolute_point <- abs(point)

max_value <- max(absolute_point, na.rm = TRUE)

max_pos <- which(absolute_point == max_value, arr.ind = TRUE)

rowname <- rownames(point)[max_pos[1]]
colname <- colnames(point)[max_pos[2]]


# Remove outliers
data <- data[-max_pos[1],]
metadata <- metadata[-max_pos[1],]


# Normalize again
set.seed(123)
sum_data <- rowSums(data)
normalized_data <- sweep(data, 1, sum_data, "/")

pca_normalized <- prcomp(normalized_data, scale = TRUE)
```

# Plot full normalized PCA without outliers with ggplot
```{r}
ggplot(pca_normalized$x,
       aes(x = PC1,
           y = PC2, 
           shape = metadata$replicate,
           size = metadata$A_B_vector,
           color = metadata$time_stamp))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Normalized PCA", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### CANVIAR EXPLICACIÓ
Here it stays the same as before because when we scale and normalize the data what we are doing is minimizing noise because of the absolute gene expression differences and focusing on relative patterns between samples. This analysis displays a better result of our data. 


# tSNE representation
```{r}
maximum_perplexity <- (nrow(normalized_data) - 1) / 3 

# Unscaled tSNE
unscaled_tsne <- Rtsne(data, dims = 2, perplexity = maximum_perplexity/2) 

# If we add verbose = TRUE it will tell us the error value for each 50 iterations until the maximum iterations default value, but it is unnecessary text. The tSNE is performed well for each case.

unscaled_tsne_data <- data.frame(unscaled_tsne$Y, 
                                 replicate = metadata$replicate, A_B_vector = metadata$A_B_vector, time_stamp = metadata$time_stamp)

colnames(unscaled_tsne_data) <- c("Dim1", "Dim2", "Replicate", "Type", "Time")


# Scaled tSNE
scaled_data <- scale(data)

scaled_tsne <- Rtsne(scaled_data, dims = 2, perplexity = maximum_perplexity/2)

scaled_tsne_data <- data.frame(scaled_tsne$Y, replicate = metadata$replicate, A_B_vector = metadata$A_B_vector, time_stamp = metadata$time_stamp)
colnames(scaled_tsne_data) <- c("Dim1", "Dim2", "Replicate", "Type", "Time")


#Normalized
sum_data <- rowSums(data)
normalized_data <- sweep(data, 1, sum_data, "/")

normalized_tsne <- Rtsne(normalized_data, dims = 2, 
                         perplexity = maximum_perplexity/2)

normalized_tsne_data <- data.frame(normalized_tsne$Y, 
                                   replicate = metadata$replicate, A_B_vector = metadata$A_B_vector, time_stamp = metadata$time_stamp)

colnames(normalized_tsne_data) <- c("Dim1", "Dim2", "Replicate", "Type", "Time")
```

# tSNE plots
# Unscaled tSNE plot

```{r}
ggplot(unscaled_tsne_data, aes(x = Dim1, y = Dim2, shape = Replicate, size = Type, color = Time))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Unscaled tSNE plot", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### CANVIAR EXPLICACIÓ
This plot shows that the samples cluster based on replicate and type. We can see that one sample stands out as an outlier, far away from the rest. Most of the other samples group together, but there isn’t a clear separation between experiment types (A or B). Some grouping by replicate is visible based on color, but overall, this plot doesn't give us much useful information beyond confirming that some samples are different. Since the data wasn’t scaled, genes with higher expression may dominate the result and hide smaller patterns.


# Scaled tSNE plot

```{r}
ggplot(scaled_tsne_data, aes(x = Dim1, y = Dim2, shape = Replicate, size = Type, color = Time))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Scaled tSNE plot", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```

### REVISAR EXPLICACIÓ
In this plot the samples are now clearly grouped by replicate, shown by color. Each replicate forms its own tight cluster, and these clusters are well separated from each other. This suggests that the scaling helped reduce the effect of genes with very high expression, making differences between replicates easier to see. However, the experiment type doesn't seem to influence the grouping much here, meaning the replicate effect is stronger than the experiment effect with this data.


# Normalized tSNE plot

```{r}
ggplot(normalized_tsne_data, aes(x = Dim1, y = Dim2, shape = Replicate, size = Type, color = Time))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(title = "Normalized tSNE plot", 
         size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()
```
### REVISAR EXPLICACIÓ
In the normalized tSNE plot, the samples continue to cluster based on replicate, similar to the scaled version. Each replicate forms a distinct group, indicating that normalization has helped adjust for gene expression differences while preserving batch effects. Unlike the unscaled plot, the outliers have been removed, reducing noise and making the overall structure clearer. However, the experiment type still does not significantly drive separation, meaning the differences between A and B are subtle compared to the influence of replicates.


# tSNE parameters

We'll only use the normalized dataset

# Reproducibility

```{r reproducibility}
set.seed(123)

plot_reproducibility <- function(normalized_data, metadata){
  
  set.seed(123)
  maximum_perplexity <- (nrow(normalized_data) - 1) / 3
  data <- Rtsne(normalized_data, perplexity = maximum_perplexity / 2)
  
  tsne_plots <- ggplot(data$Y, aes(x=data$Y[,1], y=data$Y[,2], shape=metadata$replicate, size = metadata$A_B_vector, color = metadata$time_stamp))+
    geom_point()+  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(x="tSNE 1", y="tSNE 2", shape="Replicate", size = "Experiment Label", color = "Time")+
    theme_minimal()
  
  return(tsne_plots)
}


reproducibility_values <- list()

for (i in 1:4){
  
  rep_plot <- plot_reproducibility(normalized_data, metadata)+ggtitle(paste0(i, " tSNE repetition"))
  reproducibility_values[[i]] <- rep_plot
}

#Extract legend
reproducibility_legend<-get_legend(reproducibility_values[[1]])

no_legend_reproducibility <- lapply(reproducibility_values, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_reproducibility, ncol = 2),
  reproducibility_legend,
  ncol=2,
  widths = c(10, 1),
  top="tSNE Repetitions"
)

```

To make these plots we need the set.seed() command since if we don't establish a seed we'd get different results each time. Not only that, but also we'd get different results for each plot each time meaning we'd get 4 different plots each time, not 4 of the same and with each execution it'd change. 


# Perplexity
```{r perplexity}


PerplexityPlotter <- function(normalized_data, metadata, pr){
  
  set.seed(123)
  model <- Rtsne(normalized_data, perplexity = pr)
  tsne_plots <- ggplot(model$Y, aes(model$Y[,1],
                       model$Y[,2],
                       shape = metadata$replicate,
                       size = metadata$A_B_vector, color = metadata$time_stamp))+
    geom_point()+
    scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(x = "tSNE 1", y = "tSNE 2", shape = "Replicate", size = "Type", color = "Time", title=paste0("tSNE plot for perplexity=", round(pr, 2)))
  return(tsne_plots)
}

maximum_perplexity <- (nrow(normalized_data) - 1) / 3 

test_perplexity_values <- c(1, maximum_perplexity/3, (maximum_perplexity/3) * 2, maximum_perplexity)

perplexity_plots <- list()

for (i in seq_along(test_perplexity_values)){
  per_val <- test_perplexity_values[i]
  per_plot <- PerplexityPlotter(normalized_data, metadata, per_val)
  perplexity_plots[[i]] <- per_plot
}

perplexity_legend <- get_legend(perplexity_plots[[1]])

no_legend_perplexity <- lapply(perplexity_plots, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_perplexity, ncol = 2),
  perplexity_legend,
  ncol = 2,
  widths = c(10, 1),
  top = "tSNE Perplexity"
)

```


Low perplexity values will make clusters too tight/defined. When raising the perplexity value, these clusters reorganize themselves into less number of clusters with more samples in each cluster. In the maximum perplexity value we see the extreme case which is 2 clusters really far apart from each other. The ideal value would be half of this maximum perplexity value. 



# Iterations

```{r iterations}

plot_iterations<-function(normalized_data, metadata, num_iterations){
  set.seed(123)
  
  maximum_perplexity <- (nrow(normalized_data)-1)/3
  data <- Rtsne(normalized_data, perplexity = maximum_perplexity / 2, max_iter = num_iterations)

  tsne_plots <- ggplot(data$Y, aes(x=data$Y[,1], y=data$Y[,2], 
                          shape = metadata$replicate, size = metadata$A_B_vector, color = metadata$time_stamp))+
    geom_point()+
    scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(x="tSNE 1", y="tSNE 2", shape = "Replicate", size = "Type", color = "Time",
         title=paste0(num_iterations, " iterations tSNE plot"))
  return(tsne_plots)
}

iterations<-c(2, 100, 2000, 10000)

iterations_plots <- list()

for (i in seq_along(iterations)){
  iter_num <- iterations[i]
  iter_plot <- plot_iterations(normalized_data, metadata, iter_num)
  iterations_plots[[i]] <- iter_plot
}

iterations_legend <- get_legend(iterations_plots[[1]])

no_legend_iterations <- lapply(iterations_plots, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_iterations, ncol = 2),
  iterations_legend,
  ncol=2,
  widths = c(10, 1),
  top="tSNE Iterations"
)
```

Since the number of iterations controls how long the algorithm refines the embedding, running fewer iterations can result in an underdeveloped structure, while more iterations allow the algorithm to better separate and position the points.

This can clearly be seen at iteration 2, since there is almost no visible clustering whereas in iteration 10000, the clusters are highly distinct (even overly refined) The intermediate iterations show a progressive improvement, with increasingly well-defined clusters.




# UMAP Representation

# UMAP plots
```{r}
plot_umap <- function(data, metadata){
  umap_plots <- ggplot(data$layout, aes(x = data$layout[,1], y = data$layout[,2], shape = metadata$replicate, size = metadata$A_B_vector, color = metadata$time_stamp))+
    geom_point()+
    scale_shape_manual(values = c(1, 5, 10, 15))+
    scale_size_manual( values = c(3, 5))+
    scale_color_viridis_d(option = "magma")+
    labs(x = "X", y = "Y", shape = "Replicate", size = "Type", color = "Time")+
    theme_minimal()
  
  return(umap_plots)
}
```


# Raw data UMAP plot
```{r}
umap_raw_plot <- umap(data)

plot_umap(umap_raw_plot, metadata)+
  labs(title = "UMAP Raw data plot")
```

# Normalized data UMAP plot
```{r}
umap_normalized_plot <- umap(normalized_data)

plot_umap(umap_normalized_plot, metadata)+
  labs(title = "UMAP Normalized data plot")
```

# Predict the UMAP
```{r}
umap_training <- metadata$replicate %in% c("1", "2", "3")

umap_rep4_data <- normalized_data[umap_training, ]

metadata_train <- metadata[umap_training, ]

umap_train <- umap(umap_rep4_data)

plot_umap(umap_train, metadata_train)+
  labs(title = "UMAP data Replicates 1-3")
```



```{r}
rep4_umap <- predict(umap_train, rep4)

rep4_metadata <- metadata[!umap_training, ]

rep4_data <- data.frame(Dim1 = rep4_umap[,1], Dim2 = rep4_umap[,2], Type = rep4_metadata$A_B_vector, Time = rep4_metadata$time_stamp)


ggplot(rep4_data, aes(x = Dim1, y = Dim2, shape = Type, color = Time))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_color_viridis_d(option = "magma")+
  labs(title = "Prediction for Replicate 4")+
  theme_minimal()
```
# Parameter exploration: n_neighbors
```{r warning=FALSE}
neighbor_plotter <- function(data, metadata, num){
  n_neigh_umap <- umap(data, n_neighbors = num)
  umap_plot <- plot_umap(n_neigh_umap, metadata)
  umap_plot <- umap_plot+
    labs(title=paste0("Neighbors: ", num))
  
  return(umap_plot)
}

neighbor_plots <- list()

neighbors <- seq(2, nrow(normalized_data), by = 10)

for (i in seq_along(neighbors)){
  num <- neighbors[i]
  num_plot <- neighbor_plotter(normalized_data, metadata, num)
  neighbor_plots[[i]] <- num_plot
}

neighbor_legend <- get_legend(neighbor_plots[[1]])

no_legend_neighbor <- lapply(neighbor_plots, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_neighbor, ncol = 2),
  neighbor_legend,
  ncol = 2,
  widths = c(10, 1),
  top="UMAP Neighbors"
)
```


# Parameter exploration: min_dist
```{r warning=FALSE}

min_dist_plotter <- function(data, metadata, dist_value){
  
  min_dist_umap <- umap(data, min_dist = dist_value)
  umap_plot <- plot_umap(min_dist_umap, metadata)
  umap_plot <- umap_plot+
    labs(title=paste0("Minimum distance: ", dist_value))
  
  return(umap_plot)
  
}

min_dist_list <- list()

distances <- c(0.1, 0.3, 0.5, 0.7, 0.9)

for (i in seq_along(distances)){
  min <- distances[i]
  min_dist_plot <- min_dist_plotter(normalized_data, metadata, min)
  min_dist_list[[i]] <- min_dist_plot
}

min_dist_legend <- get_legend(min_dist_list[[1]])

no_legend_min_dist <- lapply(min_dist_list, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_min_dist, ncol = 2),
  min_dist_legend,
  ncol = 2,
  widths = c(10, 1),
  top="UMAP Minimum Distance"
)


```



# Parameter exploration: n_epochs
```{r}
epoch_plotter <- function(data, metadata, epoch){
  epoch_umap <- umap(data, n_epochs = epoch)
  umap_plot <- plot_umap(epoch_umap, metadata)
  umap_plot <- umap_plot+
    labs(title=paste0("Number of iterations: ", epoch))
  
  return(umap_plot)
}


epoch_list <- list()

epoch_values <- c(100, 500, 1000, 2000)

for (i in seq_along(epoch_values)){
  num <- epoch_values[i]
  epoch_plot <- epoch_plotter(normalized_data, metadata, num)
  epoch_list[[i]] <- epoch_plot
}

epoch_legend <- get_legend(epoch_list[[1]])

no_legend_epoch <- lapply(epoch_list, "+", theme(legend.position = "none"))

grid.arrange(
  arrangeGrob(grobs = no_legend_epoch, ncol = 2),
  epoch_legend,
  ncol=2,
  widths = c(10, 1),
  top="UMAP Number of iterations"
)
```



# Final interpretation

We'll use the normalized data with outliers removed since it is the one that represents our data most accurately


# Final PCA
```{r final_pca}
final_pca1 <- ggplot(pca_normalized$x,
                     aes(x = PC1, y = PC2, shape = metadata$replicate, size = metadata$A_B_vector, color = metadata$time_stamp))+
  geom_point()+
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
    labs(size = "Type", 
         shape = "Replicate", 
         color = "Time")+
  theme_minimal()



final_pca2 <- fviz_pca_ind(pca_normalized,              geom.ind = "point", 
             habillage = metadata$A_B_vector,
             addEllipses = TRUE) +
  labs(x = "PC1", y = "PC2")+
  theme_minimal()

final_pca1 + final_pca2 + plot_annotation(title = "Final PCA representation with accurate data")

```


We observe that our data has been grouped into two clusters, which are classified by the type of experiment (not the replicate where they come from) and this means that the variance that is seen between PC1 and PC2 has to be explained by biological factors. Since the groups are clearly separated, we can confirm that the batch effect has been eliminated. 

# Final tSNE representation


```{r}
set.seed(123)

maximum_perplexity <- (nrow(normalized_data) - 1) / 3

ggplot(normalized_tsne_data, aes(x = Dim1, y = Dim2, shape = metadata$replicate, size = metadata$A_B_vector, color = metadata$time_stamp)) +
  geom_point() +
  scale_shape_manual(values = c(1, 5, 10, 15))+
  scale_size_manual( values = c(3, 5))+
  scale_color_viridis_d(option = "magma")+
  labs(title = "Final tSNE representation with accurate data", 
       x = "Dim1", y = "Dim2", shape = "Replicate", size = "Type", color = "Time") +
  theme_minimal()
```



The t-SNE plot shows how samples group based on how similar they are, and it helps support what we saw with the PCA. In our plot, the samples are grouped more by their experimental type (A/B) than what replicate they came from. This suggests that the differences in the data are due to real biological effects, not technical issues like batch effects. This supports the PCA representation since both PCA and tSNE are clustered the same way.



# Final interpretation

PCA and tSNE both help understand the main differences in our data. PCA showed clear clusters in the first two components, and tSNE showed a similar pattern in its two main dimensions. Looking back at the results, the fact that both methods show the same clear grouping gives us more confidence in what we're seeing. Since the clusters match the experiment type rather than the replicate where it comes from, we can say that the variation is likely caused by biology, not technical errors.
